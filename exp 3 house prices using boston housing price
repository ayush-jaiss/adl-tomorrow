import tensorflow as tf
from tensorflow import keras
import numpy as npimport pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

from keras.datasets import boston_housing
# Load dataset
(train_data, train_labels),(test_data, test_labels) = boston_housing.load_data()
# Display dataset shape
print("Training Data Shape:", train_data.shape)
print("Test Data Shape:", test_data.shape)
# Feature Names (from Boston Housing dataset)
feature_names = [
"CRIM", "ZN", "INDUS", "CHAS", "NOX", "RM", "AGE", "DIS",
"RAD", "TAX", "PTRATIO", "B", "LSTAT"]
# Convert to Pandas DataFrame for visualization
df = pd.DataFrame(train_data, columns=feature_names)
df["Price"] = train_labels # Add price column
#Display first 5 rows
print(df.head())

scaler = StandardScaler()
train_data = scaler. fit_transform(train_data)
test_data = scaler.transform(test_data)

from tensorflow.keras.regularizers import 12

from tensorflow.keras.callbacks import EarlyStopping

# Build the updated model with regularization and dropout

model = keras.Sequential([
keras.layers.Dense(128, activation='relu', kernel_regularizer=12(@.01), input_shape=(train_data.shape[1],)),
keras.layers.Dropout(@.3), # Drops 3@% of neurons randomly
keras.layers.Dense(64, activation=‘relu', kernel_regularizer=12(@.@1)),
keras. layers .Dropout(@.3),
keras.layers.Dense(32, activation='relu'),
keras.layers.Dense(1) # Output layer for regression

1)

# Compile the model with a reduced learning rate

optimizer = keras.optimizers.Adam(learning_rate=@.001)

model. compile(optimizer=optimizer, loss='mse', metrics=['mae'])

# Display updated model architecture

model. summary()

# Apply early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
# Train the updated model
history = model.fit(train_data, train_labels, epochs=150,
validation_data=(test_data, test_labels),batch_size=16,
callbacks=[early_stopping])

# Evaluate on test data
test_loss, test_mae = model.evaluate(test_data, test_labels)
print("\nUpdated Model Mean Absolute Error:", test_mae)

plt.plot(history.history["loss'], label="Training Loss')
plt.plot(history.history[’val_loss'], label='Validation Loss’)
plt.xlabel('Epochs')

plt.ylabel('Mean Squared Error’)

plt.legend()

plt.title('Loss Curve')
plt.show()

# Predict on test data
predictions = model.predict(test_data)
# Compare actual vs. predicted prices
plt.scatter(test_labels, predictions)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices”)
plt.title("Actual vs Predicted Prices")
plt.show{)


from sklearn.metrics import r2_score
# Get actual house prices from the test set
y_actual = test_labels
# Get predicted house prices from the model
y_predicted = model.predict(test_data).flatten()
# Compute R? Score
r2 = r2_score(y_actual, y_predicted)
print("Updated Model R? Score:", r2)
